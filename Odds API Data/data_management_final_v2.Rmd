---
title: "Data_Management_Final_cleaning_v1"
output: html_document
date: "2025-11-06"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Install Library
```{r}
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(rlang)
library(lubridate)
library(hms)
library(tibble)
library(hoopR)
library(purrr)
```

# Read Data
data: NFL
data2: NBA
```{r}
# --- Install and load required package ---
if (!requireNamespace("jsonlite", quietly = TRUE)) {
  install.packages("jsonlite")
}
library(jsonlite)

# --- Step 1: Set the raw GitHub URL ---
url <- "https://raw.githubusercontent.com/pintchom/Prediction-Markets-VS-Sports-Books/main/data/nfl_sportsbook_odds.json"
url2 <- "https://raw.githubusercontent.com/pintchom/Prediction-Markets-VS-Sports-Books/refs/heads/main/data/nba_sportsbook_odds.json"
# --- Step 2: Read JSON directly from GitHub ---
data <- fromJSON(url, flatten = TRUE)
data2 <-fromJSON(url2, flatten = TRUE)
# --- Step 3: Inspect the data ---
#str(data)       # show structure of the JSON
#head(data)      # preview first few rows

df<-data$sportsbook_odds
df2<-data2$sportsbook_odds
# df2|>glimpse()
```

#Clean Data
## 1) ID columns (kept) vs odds columns (reshaped)
```{r}
odds_cols <- names(df)[grepl("^bookmaker_odds\\.", names(df))]
id_cols   <- setdiff(names(df), odds_cols)

odds_cols2 <- names(df2)[grepl("^bookmaker_odds\\.", names(df2))]
id_cols2   <- setdiff(names(df2), odds_cols2)
```

## 2) Pivot longer (melt all bookmaker_ columns)
```{r}
df_long <- df %>%
  pivot_longer(
    cols = all_of(odds_cols),
    names_to  = "key",
    values_to = "value"
  )

df_long2 <- df2 %>%
  pivot_longer(
    cols = all_of(odds_cols2),
    names_to  = "key",
    values_to = "value"
  )
```

## 3) Parse the key into fields (robust to MyBookie.ag)
```{r}
df_long <- df_long %>%
  extract(
    key,
    into  = c("bookmaker", "market_type", "team_or_side", "value_type"),
    regex = "^bookmaker_odds\\.(.+?)\\.(h2h|spreads|totals)\\.(.+)\\.(price|point)$",
    remove = TRUE
  )

df_long2 <- df_long2 %>%
  extract(
    key,
    into  = c("bookmaker", "market_type", "team_or_side", "value_type"),
    regex = "^bookmaker_odds\\.(.+?)\\.(h2h|spreads|totals)\\.(.+)\\.(price|point)$",
    remove = TRUE
  )

```

## 4) Clean types & drop empty rows
```{r}
df_long <- df_long %>%
  mutate(value = suppressWarnings(as.numeric(value))) #|>filter(!is.na(value))

df_long2 <- df_long2 %>%
  mutate(value = suppressWarnings(as.numeric(value))) #|>filter(!is.na(value))
```


## 5) Remove rows with unmatched team_or_side
### 1. Trim whitespace on the key fields (safe even if already clean)
```{r}
df_long <- df_long %>%
  mutate(
    team_or_side = str_trim(team_or_side),
    home_team    = str_trim(home_team),
    away_team    = str_trim(away_team)
  )

df_long2 <- df_long2 %>%
  mutate(
    team_or_side = str_trim(team_or_side),
    home_team    = str_trim(home_team),
    away_team    = str_trim(away_team)
  )
```

### 2. Define totals labels
```{r}
totals_sides <- c("Over", "Under")

```

### 3. Apply filter rule
```{r}
df_long_filtered <- df_long |>
  filter(
    team_or_side %in% totals_sides |                       # keep totals
    team_or_side == home_team | team_or_side == away_team |# match a team
    !is.na(value)                                          # or keep if it has a value
  )

df_long_filtered2 <- df_long2 |>
  filter(
    team_or_side %in% totals_sides |                       # keep totals
    team_or_side == home_team | team_or_side == away_team |# match a team
    !is.na(value)                                          # or keep if it has a value
  )

```

### 4. check expection
```{r}
# df_mismatch_valued <- df_long %>%
#   dplyr::filter(
#     !(team_or_side %in% totals_sides),  # not Over/Under
#     team_or_side != home_team,          # not home
#     team_or_side != away_team,          # not away
#     !is.na(value)                       # but still has a value
#   )
# has_mismatch_valued <- nrow(df_mismatch_valued) > 0
# has_mismatch_valued # FALSE
# nrow(df_mismatch_valued) #0

```

## 6) Clean markets_collectecd column
```{r}
df_long_filtered <- df_long_filtered %>%
  dplyr::mutate(
    markets_collected = vapply(markets_collected, function(x) paste(x, collapse = ","), character(1))
  )
# class(df_long_filtered$markets_collected) #chr
# 
# df_long_filtered|>group_by(markets_collected)|>summarize(count=n()) #all totals,spreads,h2h

df_long_filtered2 <- df_long_filtered2 %>%
  dplyr::mutate(
    markets_collected = vapply(markets_collected, function(x) paste(x, collapse = ","), character(1))
  )

```

## 7) clean date and merge nfl schedule
### 1. import nfl schedule
```{r}
library(nflreadr)
nfl_schedule <- load_schedules(2025) |>
  select(
    season, game_type, week,
    gameday, weekday, gametime,
    away_team, away_score,
    home_team, home_score
  ) |>
  mutate(
    gameday  = ymd(gameday),                # Date
    gametime = paste0(gametime, ":00")      # "20:20:00" as character
  )
```

### 2. standardize team name for nfl schedule data
```{r}
team_dict <- tibble::tibble(
  abbr = c(
    "ARI","ATL","BAL","BUF","CAR","CHI","CIN","CLE","DAL","DEN","DET","GB",
    "HOU","IND","JAX","KC","LA","LAC","LV","MIA","MIN","NE","NO","NYG","NYJ",
    "PHI","PIT","SEA","SF","TB","TEN","WAS"
  ),
  full = c(
    "Arizona Cardinals", "Atlanta Falcons", "Baltimore Ravens", "Buffalo Bills",
    "Carolina Panthers", "Chicago Bears", "Cincinnati Bengals", "Cleveland Browns",
    "Dallas Cowboys", "Denver Broncos", "Detroit Lions", "Green Bay Packers",
    "Houston Texans", "Indianapolis Colts", "Jacksonville Jaguars",
    "Kansas City Chiefs", "Los Angeles Rams", "Los Angeles Chargers",
    "Las Vegas Raiders", "Miami Dolphins", "Minnesota Vikings",
    "New England Patriots", "New Orleans Saints", "New York Giants",
    "New York Jets", "Philadelphia Eagles", "Pittsburgh Steelers",
    "Seattle Seahawks", "San Francisco 49ers", "Tampa Bay Buccaneers",
    "Tennessee Titans", "Washington Commanders"
  )
)

nfl_schedule <- nfl_schedule |>
  left_join(team_dict, by = c("home_team" = "abbr")) |>
  rename(home_team_full = full) |>
  left_join(team_dict, by = c("away_team" = "abbr")) |>
  rename(away_team_full = full) |>
  mutate(
    home_team = home_team_full,
    away_team = away_team_full
  ) |>
  select(-home_team_full, -away_team_full)



```

### 3. merge with odds data 
```{r}
df_long_filtered <- df_long_filtered |>
  mutate(
    # parse as UTC
    game_start_utc = ymd_hms(game_start, tz = "UTC"),
    # convert to Eastern
    game_start_et  = with_tz(game_start_utc, "America/New_York"),
    # extract date/time for joining
    game_date_et   = as.Date(game_start_et),
    game_time_et   = format(game_start_et, "%H:%M:%S")  # "20:20:00"
  ) |>
  inner_join(
    nfl_schedule,
    by = c(
      "home_team"    = "home_team",
      "away_team"    = "away_team",
      "game_date_et" = "gameday",
      "game_time_et" = "gametime"
    )
  )
  
```

## 8) clean date and merge NBA schedule
### 1. import NBA schedule
```{r}
library(hoopR)
# All calendar dates in 2025
dates_2025 <- seq(as.Date("2025-01-01"), as.Date("2025-12-31"), by = "day")

# Fetch games for each date and combine
scores_2025 <- map_dfr(
  dates_2025,
  ~ {
    season_arg <- format(.x, "%Y%m%d")
    message("Fetching: ", season_arg)
    tryCatch(
      espn_nba_scoreboard(season = season_arg),
      error = function(e) NULL   # skip days with issues
    )
  }
)

# Optional: keep only games actually played in 2025 (should already be true)
scores_2025 <- scores_2025 %>%
  mutate(game_date = as_date(game_date)) %>%
  filter(game_date >= as_date("2025-01-01"),
         game_date <= as_date("2025-12-31"))

scores_2025_final <- scores_2025 %>%
  filter(status_name == "STATUS_FINAL") %>%  # or status_name == "Final" depending on your version
  select(
    game_id,
    game_date,
    home_team_full_name,
    home_score,
    away_team_full_name,
    away_score
  )

```

### 2. standardize team name
```{r}
scores_2025_std <- scores_2025_final %>%
  # remove any gimmick teams if present
  filter(
    !home_team_full_name %in% c("Team Chuck", "Team Shaq"),
    !away_team_full_name %in% c("Team Chuck", "Team Shaq")
  ) %>%
  mutate(
    # keep ESPN's date but rename it so it doesn't overwrite ours
    espn_game_date = as.Date(game_date),

    # standardize names to match Odds API
    home_team = dplyr::recode(
      home_team_full_name,
      "LA Clippers" = "Los Angeles Clippers",
      .default = home_team_full_name
    ),
    away_team = dplyr::recode(
      away_team_full_name,
      "LA Clippers" = "Los Angeles Clippers",
      .default = away_team_full_name
    )
  ) %>%
  select(
    game_id_espn = game_id,
    espn_game_date,
    home_team,
    away_team,
    home_score,
    away_score
  )

```

### 3. Merge final scores into df_long_filtered2
```{r}
df_long_filtered2_dates <- df_long_filtered2 %>%
  # drop any old game_date so we start fresh
  mutate(
    # parse game_start string as UTC
    game_start_utc = ymd_hms(game_start, tz = "UTC"),
    game_start_et  = with_tz(game_start_utc, "America/New_York"),
    game_date      = as.Date(game_start_utc, tz = "America/New_York")
  )


df_with_scores <- df_long_filtered2_dates %>%
  left_join(
    scores_2025_std,
    by = c("home_team", "away_team", "game_date" = "espn_game_date")
  )

# check mismatch
df_with_scores %>%
  summarise(
    total_rows  = n(),
    matched     = sum(!is.na(home_score)),
    unmatched   = sum(is.na(home_score))
  )

df_with_scores %>%
  filter(is.na(home_score)) %>%
  distinct(home_team, away_team, game_date) %>%
  arrange(game_date) %>%
  head(40)

```
### 4. edge case_nba - home/away swap
```{r}
# df_with_scores is your current merged table (most games matched already)
# scores_2025_std is the standardized ESPN table we used before

# 1) Split into matched and unmatched
matched_games <- df_with_scores %>%
  filter(!is.na(home_score))

unmatched_games <- df_with_scores %>%
  filter(is.na(home_score))

# 2) For the unmatched rows, try joining with home/away swapped
unmatched_fixed <- unmatched_games %>%
  # drop any old ESPN result columns so join is clean
  select(-game_id_espn, -home_score, -away_score) %>%
  left_join(
    scores_2025_std,
    by = c(
      "home_team" = "away_team",      # swap here
      "away_team" = "home_team",      # and here
      "game_date" = "espn_game_date"
    )
  )

# 3) Combine back together: original matches + fixed swapped ones
df_with_scores_fixed <- bind_rows(
  matched_games,
  unmatched_fixed
)

df_with_scores_fixed %>%
  summarise(
    total_rows  = n(),
    matched     = sum(!is.na(home_score)),
    unmatched   = sum(is.na(home_score))
  )

```

### 5. edge case_nba - game_id duplicate
```{r}
df_with_scores_clean <- df_with_scores_fixed %>%
  # find game_ids that actually correspond to more than one game
  group_by(game_id) %>%
  mutate(
    n_dates = n_distinct(game_date),
    game_id_unique = if_else(
      n_dates > 1,
      paste0(game_id, "_", format(game_date, "%Y%m%d")),  # make them unique
      game_id
    )
  ) %>%
  ungroup() %>%
  select(-n_dates)
```





#Summary Stats
## 1) General Check
### 1. Number of Distinct Game
```{r}
# df <- df_long_filtered
# total_games <- dplyr::n_distinct(df$game_id)
# total_games #105
```
### 2. Number of Rows per Distinct Game
```{r}
# df|>group_by(game_id)|>
#   summarize(count=n())|>
#   ungroup()|>summary()
# # each game has 264 rows
# # example of one game
# # df_test<-df|>filter(game_id == "016f76d8237e8d4eb62b9c2ef68381bb")


```

### 3.Distribution of total_book per game
```{r}
# bookmakers_per_game <- df |>
#   dplyr::distinct(game_id, total_bookmakers)
# 
# summary(bookmakers_per_game$total_bookmakers)
# dplyr::count(bookmakers_per_game, total_bookmakers, name = "games") |>
#   dplyr::arrange(dplyr::desc(games))



```

### 4. % of games with each market
```{r}
# market_presence <- df %>%
#   dplyr::distinct(game_id, market_type) %>%
#   dplyr::count(market_type, name = "games_with_market") %>%
#   dplyr::mutate(pct_of_games = 100 * games_with_market / total_games) %>%
#   dplyr::arrange(dplyr::desc(games_with_market))
# 
# market_presence

```

## 2) Graph
### 1. Moneyline price("price) distribution (all H2H prices)
```{r}
# df_ml <- df %>%
#   filter(market_type == "h2h", value_type == "price", !is.na(value))
# 
# ggplot(df_ml, aes(x = value)) +
#   geom_histogram(binwidth = 20) +
#   labs(title = "Moneyline Prices (All H2H)", x = "Price (American odds)", y = "Count")

```

### 2. favorites vs. underdogs based on moneyline(H2H, price)
```{r}
# df_ml2 <- df_ml %>%
#   mutate(side_type = ifelse(value < 0, "favorite", "underdog"))
# 
# ggplot(df_ml2, aes(x = value)) +
#   geom_histogram(binwidth = 20) +
#   facet_wrap(~ side_type, scales = "free_y") +
#   labs(title = "Moneyline Prices by Side Type", x = "Price (American odds)", y = "Count")

```

### 3. Spread lines(spreads, point): favorites (neg) vs underdogs (pos)
```{r}
# df_sp <- df %>%
#   filter(market_type == "spreads", value_type == "point", !is.na(value))
# spreads_by_sign <- df_sp %>%
#   mutate(line_side = ifelse(value < 0, "favorite_line", "underdog_line")) %>%
#   group_by(line_side) %>%
#   summarise(n = n(), mean = mean(value), median = median(value), sd = sd(value),
#             min = min(value), max = max(value), .groups = "drop")
# spreads_by_sign


```

### 4. distribution of Totals LLines(totals, point)
```{r}
# df_tot <- df %>%
#   filter(market_type == "totals", value_type == "point", !is.na(value))
# 
# ggplot(df_tot, aes(x = value)) +
#   geom_histogram(binwidth = 1) +
#   labs(title = "Totals (Over/Under) Lines", x = "Total points line", y = "Count")

```

### 5. Kalshi Price
```{r}

# ggplot(df, aes(x = kalshi_price)) +
#   geom_density(fill = "skyblue", alpha = 0.5) +
#   labs(
#     title = "Kalshi Price Density",
#     x = "Kalshi price (¢)",
#     y = "Density"
#   ) +
#   theme_minimal()


```

### check value
```{r}
# df_long_filtered|>filter(market_type == "h2h",value_type=="point", !is.na(value))

#for market type h2h with value type point, all of them are NA value
```



# Probability--Sportsbook
## 1. Filter down to "h2h" and "price"
```{r}
filter_h2h_prices <- function(
  df,
  bookmakers    = NULL,            # optional: c("DraftKings", "FanDuel", ...)
  market_type_col = "market_type", # column that says "h2h", "spreads", "totals"
  value_type_col  = "value_type",  # column that says "price" vs "point"
  bookmaker_col   = "bookmaker"    # column with sportsbook name
) {
  
  # 1. Keep only moneyline (h2h) + price rows
  df_filtered <- df |>
    dplyr::filter(
      .data[[market_type_col]] == "h2h",
      .data[[value_type_col]]  == "price"
    )
  
  # 2. If a bookmaker list is provided, filter to those
  if (!is.null(bookmakers)) {
    df_filtered <- df_filtered |>
      dplyr::filter(.data[[bookmaker_col]] %in% bookmakers)
  }
  
  # 3. Return the filtered long-format data
  df_filtered
}

# h2h_big_books <- filter_h2h_prices(
#   df         = df_long_filtered)

```


## 2. Add home-away flag
```{r}
add_home_away_flag <- function(
  df,
  home_team_col    = "home_team",
  away_team_col    = "away_team",
  team_or_side_col = "team_or_side"
) {
  # 1. Check that required columns exist
  needed_cols <- c(home_team_col, away_team_col, team_or_side_col)
  missing_cols <- setdiff(needed_cols, names(df))
  if (length(missing_cols) > 0) {
    stop(
      "add_home_away_flag(): missing required columns: ",
      paste(missing_cols, collapse = ", ")
    )
  }
  
  # 2. Add `side` and a match flag
  df_out <- df %>%
    mutate(
      side = case_when(
        .data[[team_or_side_col]] == .data[[home_team_col]] ~ "home",
        .data[[team_or_side_col]] == .data[[away_team_col]] ~ "away",
        TRUE                                                 ~ NA_character_
      ),
      is_team_match = !is.na(side)
    )
  
  # 3. warn if there are any non-matching rows
  n_bad <- sum(!df_out$is_team_match, na.rm = TRUE)
  if (n_bad > 0) {
    warning(
      "add_home_away_flag(): found ", n_bad,
      " rows where `team_or_side` did not match `home_team` or `away_team`.\n",
      "Inspect these for team-name mismatches."
    )
  }
  
  df_out
}

# h2h_with_side <- add_home_away_flag(h2h_big_books)
```

## 3. turn long rows into one row per game × bookmaker.
```{r}
# h2h_dedup <- h2h_with_side %>%
#   distinct(game_id, bookmaker, team_or_side, .keep_all = TRUE)

summarise_moneyline_by_game_bookmaker <- function(df) {
  df_summarised <- df %>%
    group_by(game_id, bookmaker) %>%
    summarise(
      # should be constant within a game
      home_team   = first(home_team),
      away_team   = first(away_team),

      # moneylines for each side
      home_ml_raw = first(value[side == "home"]),
      away_ml_raw = first(value[side == "away"]),

      # simple diagnostics
      n_home_rows = sum(side == "home", na.rm = TRUE),
      n_away_rows = sum(side == "away", na.rm = TRUE),
      .groups     = "drop"
    )

  # keep only clean game–bookmaker pairs: exactly 1 home + 1 away and no NAs
  df_clean <- df_summarised|>
    select(-n_home_rows,-n_away_rows)


  df_clean
}

summarise_moneyline_by_game_bookmaker_nba <- function(df) {
  df_summarised <- df %>%
    group_by(game_id_unique, bookmaker) %>%
    summarise(
      # should be constant within a game
      home_team   = first(home_team),
      away_team   = first(away_team),

      # moneylines for each side
      home_ml_raw = first(value[side == "home"]),
      away_ml_raw = first(value[side == "away"]),

      # simple diagnostics
      n_home_rows = sum(side == "home", na.rm = TRUE),
      n_away_rows = sum(side == "away", na.rm = TRUE),
      .groups     = "drop"
    )

  # keep only clean game–bookmaker pairs: exactly 1 home + 1 away and no NAs
  df_clean <- df_summarised|>
    select(-n_home_rows,-n_away_rows)


  df_clean
}

# ml_by_game_book <- h2h_dedup %>%
#   summarise_moneyline_by_game_bookmaker()

```


## 4. turn moneyline into probability and remove vig
```{r}
moneyline_to_prob_scalar <- function(ml) {
  ifelse(
    is.na(ml),
    NA_real_,
    ifelse(
      ml > 0,
      100 / (ml + 100),                 # underdog: +X
      abs(ml) / (abs(ml) + 100)        # favorite: -X
    )
  )
}

add_raw_implied_probs <- function(df) {
  df %>%
    mutate(
      home_prob_raw = moneyline_to_prob_scalar(home_ml_raw),
      away_prob_raw = moneyline_to_prob_scalar(away_ml_raw)
    )
}


normalize_remove_vig <- function(df) {
  df %>%
    mutate(
      overround = home_prob_raw + away_prob_raw,
      prob_home = home_prob_raw / overround,
      prob_away = away_prob_raw / overround
    )
}

# probs_by_book<-ml_by_game_book|>
#   add_raw_implied_probs()|>
#   normalize_remove_vig()

```

## 5. build the sports book probability table
```{r}
probs_by_book_nfl <- df_long_filtered %>%
  filter_h2h_prices() %>%                         # keep only h2h price rows
  add_home_away_flag() %>%                        # tag rows as home/away
  distinct(game_id, bookmaker, team_or_side,      # drop pure duplicates
           .keep_all = TRUE) %>%
  summarise_moneyline_by_game_bookmaker() %>%     # home_ml_raw / away_ml_raw
  add_raw_implied_probs() %>%                     # home_prob_raw / away_prob_raw
  normalize_remove_vig()                          # prob_home / prob_away

probs_by_book_nba <- df_with_scores_clean %>%
  filter_h2h_prices() %>%                         # keep only h2h price rows
  add_home_away_flag() %>%                        # tag rows as home/away
  distinct(game_id_unique, bookmaker, team_or_side,      # drop pure duplicates
           .keep_all = TRUE) %>%
  summarise_moneyline_by_game_bookmaker_nba() %>%     # home_ml_raw / away_ml_raw
  add_raw_implied_probs() %>%                     # home_prob_raw / away_prob_raw
  normalize_remove_vig()                          # prob_home / prob_away

```

# Brier Score & Log loss --- sportsbook

## 1. Add a home_win indicator
```{r}
# Get final scores per game from df_long_filtered (NOT nfl_schedule)
game_results_nfl <- df_long_filtered %>%
  dplyr::select(game_id, home_score, away_score) %>%
  dplyr::distinct()

game_results_nba <- df_with_scores_clean %>%
  dplyr::select(game_id_unique, home_score, away_score) %>%
  dplyr::distinct()

add_home_win <- function(df) {
  df %>%
    mutate(
      home_win = case_when(
        home_score > away_score ~ 1L,
        home_score < away_score ~ 0L,
        TRUE                    ~ NA_integer_   # ties or missing
      )
    )
}


```

## 2. Scalar Brier and log-loss helpers
```{r}
brier_error_scalar <- function(p, y) {
  (p - y)^2
}

log_loss_scalar <- function(p, y, eps = 1e-15) {
  p_clipped <- pmin(pmax(p, eps), 1 - eps)
  -(y * log(p_clipped) + (1 - y) * log(1 - p_clipped))
}


```

## 3. Generic function to add Brier / log-loss for any prob column
```{r}
add_brier_and_logloss <- function(df,
                                  prob_col    = "prob_home",
                                  outcome_col = "home_win") {
  p <- df[[prob_col]]
  y <- df[[outcome_col]]
  
  df %>%
    mutate(
      brier   = brier_error_scalar(p, y),
      logloss = log_loss_scalar(p, y)
    )
}





```

## 4. create table with brier / log-loss
```{r}
eval_nfl <- probs_by_book_nfl %>%
  inner_join(game_results_nfl, by = "game_id") %>%  # add home_score and away_score
  add_home_win() %>%                            # add home_win = 0/1
  add_brier_and_logloss(                        # compute brier/logloss
    prob_col    = "prob_home",
    outcome_col = "home_win"
  )
bookmaker_eval_nfl <- eval_nfl %>%
  group_by(bookmaker) %>%
  summarise(
    n_games      = n(),
    brier_mean   = mean(brier,   na.rm = TRUE),
    logloss_mean = mean(logloss, na.rm = TRUE),
    .groups      = "drop"
  ) %>%
  arrange(brier_mean)   # best bookmaker at top

eval_nba <- probs_by_book_nba %>%
  inner_join(game_results_nba, by = "game_id_unique") %>%  # add home_score and away_score
  add_home_win() %>%                            # add home_win = 0/1
  add_brier_and_logloss(                        # compute brier/logloss
    prob_col    = "prob_home",
    outcome_col = "home_win"
  )
bookmaker_eval_nba <- eval_nba %>%
  group_by(bookmaker) %>%
  summarise(
    n_games      = n(),
    brier_mean   = mean(brier,   na.rm = TRUE),
    logloss_mean = mean(logloss, na.rm = TRUE),
    .groups      = "drop"
  ) %>%
  arrange(brier_mean)   # best bookmaker at top



```
## test
```{r}
# # In the probs table
# counts_probs <- probs_by_book_nba %>%
#   count(game_id, name = "n_probs")
# 
# # In the results table
# counts_results <- game_results_nba %>%
#   count(game_id, name = "n_results")
# 
# many_to_many_ids <- counts_probs %>%
#   inner_join(counts_results, by = "game_id") %>%
#   filter(n_probs > 1, n_results > 1)
# 
# many_to_many_ids


```






# Log-loss and Brier Score --- Kelshi_nfl
## 0. Helper: NFL team lookup (abbr → full name)
```{r}
make_nfl_team_lookup <- function() {
  tibble::tribble(
    ~abbr, ~team_name,
    "ARI","Arizona Cardinals",
    "ATL","Atlanta Falcons",
    "BAL","Baltimore Ravens",
    "BUF","Buffalo Bills",
    "CAR","Carolina Panthers",
    "CHI","Chicago Bears",
    "CIN","Cincinnati Bengals",
    "CLE","Cleveland Browns",
    "DAL","Dallas Cowboys",
    "DEN","Denver Broncos",
    "DET","Detroit Lions",
    "GB","Green Bay Packers",
    "HOU","Houston Texans",
    "IND","Indianapolis Colts",
    "JAX","Jacksonville Jaguars",
    "KC","Kansas City Chiefs",
    "LV","Las Vegas Raiders",
    "LAC","Los Angeles Chargers",
    "LAR","Los Angeles Rams",
    "MIA","Miami Dolphins",
    "MIN","Minnesota Vikings",
    "NE","New England Patriots",
    "NO","New Orleans Saints",
    "NYG","New York Giants",
    "NYJ","New York Jets",
    "PHI","Philadelphia Eagles",
    "PIT","Pittsburgh Steelers",
    "SF","San Francisco 49ers",
    "SEA","Seattle Seahawks",
    "TB","Tampa Bay Buccaneers",
    "TEN","Tennessee Titans",
    "WAS","Washington Commanders"
  )
}

```

## 1. Add raw Kalshi probability (price → decimal)
```{r}
add_kalshi_prob <- function(df) {
  df %>%
    dplyr::mutate(
      kalshi_prob_raw = dplyr::case_when(
        !is.na(kalshi_price) ~ kalshi_price / 100,                           # cents → decimal
        !is.na(kalshi_yes_bid) & !is.na(kalshi_yes_ask) ~
          (kalshi_yes_bid + kalshi_yes_ask) / 200,                           # midpoint /100
        TRUE ~ NA_real_
      )
    )
}

```

## 2. Parse YES side abbreviation from kalshi_ticker
```{r}
parse_kalshi_yes_abbrev <- function(df) {
  df %>%
    dplyr::mutate(
      kalshi_yes_abbrev = stringr::str_extract(kalshi_ticker, "[A-Z]{2,3}$")
    )
}

```

## 3. Attach full YES team name (using lookup)
```{r}
attach_kalshi_yes_team <- function(df, team_lookup) {
  df %>%
    dplyr::left_join(team_lookup, by = c("kalshi_yes_abbrev" = "abbr")) %>%
    dplyr::rename(kalshi_yes_team = team_name)
}

```

## 4. Turn Kalshi YES into home/away probabilities
```{r}
add_kalshi_home_away_prob <- function(df) {
  df %>%
    dplyr::mutate(
      kalshi_prob_home = dplyr::case_when(
        is.na(kalshi_prob_raw) ~ NA_real_,
        kalshi_yes_team == home_team ~ kalshi_prob_raw,        # YES = home wins
        kalshi_yes_team == away_team ~ 1 - kalshi_prob_raw,    # YES = away wins → home prob = 1 - p
        TRUE ~ NA_real_
      ),
      kalshi_prob_away = dplyr::case_when(
        is.na(kalshi_prob_raw) ~ NA_real_,
        kalshi_yes_team == away_team ~ kalshi_prob_raw,
        kalshi_yes_team == home_team ~ 1 - kalshi_prob_raw,
        TRUE ~ NA_real_
      )
    )
}

```

## 5. Collapse to one row per game with outcome
```{r}
build_game_level_outcomes <- function(df) {
  df %>%
    dplyr::group_by(
      game_id, home_team, away_team,
      season, week, game_date_et
    ) %>%
    dplyr::summarise(
      kalshi_prob_home = dplyr::first(kalshi_prob_home),
      kalshi_prob_away = dplyr::first(kalshi_prob_away),
      home_score       = dplyr::first(home_score),
      away_score       = dplyr::first(away_score),
      .groups = "drop"
    ) %>%
    dplyr::mutate(
      home_win = as.integer(home_score > away_score)
    )
}

```


## 6. Compute Brier & log-loss for Kalshi
```{r}
compute_kalshi_metrics <- function(game_level_df,
                                   prob_col = kalshi_prob_home,
                                   outcome_col = home_win,
                                   eps = 1e-15) {

  df_metrics <- game_level_df %>%
    dplyr::mutate(
      .prob = {{ prob_col }},
      .y    = {{ outcome_col }},
      .prob_clipped = pmin(pmax(.prob, eps), 1 - eps),
      brier   = (.prob_clipped - .y)^2,
      logloss = dplyr::if_else(.y == 1L,
                               -log(.prob_clipped),
                               -log(1 - .prob_clipped))
    )

  summary_tbl <- df_metrics %>%
    dplyr::summarise(
      n_games    = dplyr::n(),
      brier_mean = mean(brier,   na.rm = TRUE),
      logloss_mean = mean(logloss, na.rm = TRUE)
    )|>
    mutate(bookmaker="Kalshi")

  list(
    per_game = df_metrics,
    summary  = summary_tbl
  )
}

```

## 7. Putting it all together on df_long_filtered
```{r}


team_lookup <- make_nfl_team_lookup()

df_kalshi_processed <-
  df_long_filtered %>%
  add_kalshi_prob() %>%
  parse_kalshi_yes_abbrev() %>%
  attach_kalshi_yes_team(team_lookup) %>%
  add_kalshi_home_away_prob()

kalshi_game_level_nfl <-
  build_game_level_outcomes(df_kalshi_processed)

kalshi_metrics <-
  compute_kalshi_metrics(kalshi_game_level_nfl)

kalshi_summary<-kalshi_metrics$summary     # overall Brier & log-loss
kalshi_eval<-kalshi_metrics$per_game    # per-game metrics, if you need them

```


# Log-loss and Brier Score --- Kelshi_nba
## 0. Helper: NBA team lookup (abbr → full name)
```{r}
make_nba_team_lookup <- function() {
  tibble::tribble(
    ~abbr, ~team_name,
    "ATL","Atlanta Hawks",
    "BOS","Boston Celtics",
    "BKN","Brooklyn Nets",
    "CHA","Charlotte Hornets",
    "CHI","Chicago Bulls",
    "CLE","Cleveland Cavaliers",
    "DAL","Dallas Mavericks",
    "DEN","Denver Nuggets",
    "DET","Detroit Pistons",
    "GSW","Golden State Warriors",
    "HOU","Houston Rockets",
    "IND","Indiana Pacers",
    "LAC","Los Angeles Clippers",
    "LAL","Los Angeles Lakers",
    "MEM","Memphis Grizzlies",
    "MIA","Miami Heat",
    "MIL","Milwaukee Bucks",
    "MIN","Minnesota Timberwolves",
    "NOP","New Orleans Pelicans",
    "NYK","New York Knicks",
    "OKC","Oklahoma City Thunder",
    "ORL","Orlando Magic",
    "PHI","Philadelphia 76ers",
    "PHX","Phoenix Suns",
    "POR","Portland Trail Blazers",
    "SAC","Sacramento Kings",
    "SAS","San Antonio Spurs",
    "TOR","Toronto Raptors",
    "UTA","Utah Jazz",
    "WAS","Washington Wizards"
  )
}

```

## 1. Add raw Kalshi probability
```{r}
add_kalshi_prob_nba <- function(df) {
  df %>%
    dplyr::mutate(
      kalshi_prob_raw = dplyr::case_when(
        !is.na(kalshi_price) ~ kalshi_price / 100,
        !is.na(kalshi_yes_bid) & !is.na(kalshi_yes_ask) ~
          (kalshi_yes_bid + kalshi_yes_ask) / 200,
        TRUE ~ NA_real_
      )
    )
}

```


## 2. Parse YES team from Kalshi ticker
```{r}
parse_kalshi_yes_abbrev_nba <- function(df) {
  df %>%
    dplyr::mutate(
      kalshi_yes_abbrev = stringr::str_extract(kalshi_ticker, "[A-Z]{2,4}$")
    )
}

```

## 3. Attach full NBA team name
```{r}
attach_kalshi_yes_team_nba <- function(df, team_lookup) {
  df %>%
    dplyr::left_join(team_lookup, by = c("kalshi_yes_abbrev" = "abbr")) %>%
    dplyr::rename(kalshi_yes_team = team_name)
}

```

## 4. Convert YES probabilities into home/away probs
```{r}
add_kalshi_home_away_prob_nba <- function(df) {
  df %>%
    dplyr::mutate(
      kalshi_prob_home = dplyr::case_when(
        is.na(kalshi_prob_raw) ~ NA_real_,
        kalshi_yes_team == home_team ~ kalshi_prob_raw,
        kalshi_yes_team == away_team ~ 1 - kalshi_prob_raw,
        TRUE ~ NA_real_
      ),
      kalshi_prob_away = 1 - kalshi_prob_home
    )
}

```

## 5. Collapse to one row per game
```{r}
build_game_level_outcomes_nba <- function(df) {
  df %>%
    dplyr::group_by(game_id, home_team, away_team, game_date) %>%
    dplyr::summarise(
      kalshi_prob_home = dplyr::first(kalshi_prob_home),
      kalshi_prob_away = dplyr::first(kalshi_prob_away),
      home_score       = dplyr::first(home_score),
      away_score       = dplyr::first(away_score),
      .groups = "drop"
    ) %>%
    dplyr::mutate(home_win = as.integer(home_score > away_score))
}

```


## 6. Compute Brier + Log Loss for NBA
```{r}
compute_kalshi_metrics_nba <- function(game_level_df,
                                      prob_col = kalshi_prob_home,
                                      outcome_col = home_win,
                                      eps = 1e-15) {

  df_metrics <- game_level_df %>%
    dplyr::mutate(
      .prob = {{ prob_col }},
      .y    = {{ outcome_col }},
      .prob_clipped = pmin(pmax(.prob, eps), 1 - eps),
      brier   = (.prob_clipped - .y)^2,
      logloss = dplyr::if_else(.y == 1L,
                               -log(.prob_clipped),
                               -log(1 - .prob_clipped))
    )

  summary_tbl <- df_metrics %>%
    dplyr::summarise(
      n_games      = dplyr::n(),
      brier_mean   = mean(brier,   na.rm = TRUE),
      logloss_mean = mean(logloss, na.rm = TRUE)
    ) %>%
    mutate(bookmaker="Kalshi")

  list(
    per_game = df_metrics,
    summary  = summary_tbl
  )
}

```

## 7. Full NBA Pipeline
```{r}
team_lookup_nba <- make_nba_team_lookup()

df_kalshi_processed_nba <-
  df_with_scores_clean %>%      # your cleaned odds+scores dataset
  add_kalshi_prob_nba() %>%
  parse_kalshi_yes_abbrev_nba() %>%
  attach_kalshi_yes_team_nba(team_lookup_nba) %>%
  add_kalshi_home_away_prob_nba()

kalshi_game_level_nba <-
  build_game_level_outcomes_nba(df_kalshi_processed_nba)

kalshi_metrics_nba <-
  compute_kalshi_metrics_nba(kalshi_game_level_nba)

kalshi_summary_nba <- kalshi_metrics_nba$summary
kalshi_eval_nba    <- kalshi_metrics_nba$per_game
kalshi_summary_nba
kalshi_eval_nba

```



# Organize File and Output
```{r}
# NFL
## Initial clean data from Odds API
df_long_filtered
write.csv(df_long_filtered, file = "C:/Users/Charles/Dropbox/data_management/output_data/NFL/NFL_clean_odd.csv", row.names = FALSE)

## sports book probability table
probs_by_book_nfl
write.csv(probs_by_book_nfl, file = "C:/Users/Charles/Dropbox/data_management/output_data/NFL/NFL_sportbook_prob_table.csv", row.names = FALSE)

## sports book brier score and log loss for single event
eval_nfl
write.csv(eval_nfl, file = "C:/Users/Charles/Dropbox/data_management/output_data/NFL/NFL_sportbook_evaluation_table.csv", row.names = FALSE)

## sports book average brier score and log loss
bookmaker_eval_nfl
write.csv(bookmaker_eval_nfl, file = "C:/Users/Charles/Dropbox/data_management/output_data/NFL/NFL_sportbook_summary_table.csv", row.names = FALSE)

## Kalshi probability table
kalshi_game_level_nfl
write.csv(kalshi_game_level_nfl, file = "C:/Users/Charles/Dropbox/data_management/output_data/NFL/NFL_kalshi_prob_table.csv", row.names = FALSE)

## Kalshi brier score and log loss for single event
kalshi_eval<-kalshi_metrics$per_game
write.csv(kalshi_eval, file = "C:/Users/Charles/Dropbox/data_management/output_data/NFL/NFL_kalshi_evaluation_table.csv", row.names = FALSE)

## Kalshi average Brier & log-loss summarization
kalshi_summary
write.csv(kalshi_summary, file = "C:/Users/Charles/Dropbox/data_management/output_data/NFL/NFL_kalshi_summary_table.csv", row.names = FALSE)

# NBA
## Initial clean data from Odds API
df_with_scores_clean
write.csv(df_with_scores_clean, file = "C:/Users/Charles/Dropbox/data_management/output_data/NBA/NBA_clean_odd.csv", row.names = FALSE)

## sports book probability table
probs_by_book_nba
write.csv(probs_by_book_nba, file = "C:/Users/Charles/Dropbox/data_management/output_data/NBA/NBA_sportbook_prob_table.csv", row.names = FALSE)

## sports book brier score and log loss for single event
eval_nba
write.csv(eval_nba, file = "C:/Users/Charles/Dropbox/data_management/output_data/NBA/NBA_sportbook_evaluation_table.csv", row.names = FALSE)

## sports book average brier score and log loss
bookmaker_eval_nba
write.csv(bookmaker_eval_nba, file = "C:/Users/Charles/Dropbox/data_management/output_data/NBA/NBA_sportbook_summary_table.csv", row.names = FALSE)

## Kalshi probability table
kalshi_game_level_nba
write.csv(kalshi_game_level_nba, file = "C:/Users/Charles/Dropbox/data_management/output_data/NBA/NBA_kalshi_prob_table.csv", row.names = FALSE)

## Kalshi brier score and log loss for single event
kalshi_eval_nba
write.csv(kalshi_eval_nba, file = "C:/Users/Charles/Dropbox/data_management/output_data/NBA/NBA_kalshi_evaluation_table.csv", row.names = FALSE)

## Kalshi average Brier & log-loss summarization
kalshi_summary_nba
write.csv(kalshi_summary_nba, file = "C:/Users/Charles/Dropbox/data_management/output_data/NBA/NBA_kalshi_summary_table.csv", row.names = FALSE)
```


































